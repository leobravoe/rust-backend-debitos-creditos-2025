# ==========================================================================================
# NGINX Otimizado para Benchmark de Alta Concorrência com Recursos Limitados
# Foco: Alto throughput (RPS) de pequenas requisições HTTP/1.1
# ==========================================================================================

# A diretiva 'auto' é ideal. Dado o limite de 0.2 CPU, o Nginx provavelmente usará 1 worker.
worker_processes auto;

# worker_rlimit_nofile 20000; define, por worker do Nginx, o limite máximo de descritores de 
# arquivo (FDs) que o processo pode abrir — conexões de clientes, conexões ao upstream, logs 
# etc. Em proxy reverso, cada cliente costuma consumir ~2 FDs (cliente↔Nginx e Nginx↔app), 
# então o limite precisa acompanhar o que você pede em worker_connections (regra prática: 
# FDs ≈ worker_connections × 2 + 10–20% de folga). Se o valor for baixo, surgem erros 
# “too many open files”, 5xx e caudas de latência. Garanta que o SO permita esse teto (ex.: 
# ulimit -n ou LimitNOFILE= no systemd) e então use worker_rlimit_nofile para que cada worker 
# herde o limite adequado.
worker_rlimit_nofile 20000;

# Desativa logs de erro para remover I/O de disco. Esta diretiva é permitida no contexto principal.
error_log /dev/null;

events {
    # Número de conexões por worker. Reduzido para um valor realista para 0.2 CPU e 50MB de RAM.
    worker_connections 8192;

    # Otimização para Linux: usa a forma mais eficiente de notificação de I/O.
    use epoll;

    # Permite que um worker aceite múltiplas conexões de uma vez, reduzindo a latência sob carga.
    multi_accept on;
}

http {
    # CORREÇÃO: Movido 'access_log off' para dentro do contexto 'http', onde é permitido.
    # Desativa completamente o log de acesso para economizar I/O de disco e CPU.
    access_log off;

    # Otimizações de TCP/IP para máxima eficiência e baixa latência.
    tcp_nopush on; # Envia cabeçalhos e início do corpo em um único pacote.
    tcp_nodelay on; # Envia dados imediatamente, sem aguardar para preencher o buffer.

    # Define um timeout para as conexões keep-alive com o cliente.
    keepalive_timeout 65s;

    # Quantidade máxima de requisições por conexão persistente do *cliente*.
    # Alto = menos handshakes; se notar conexões muito antigas, reduza.
    keepalive_requests 10000;
    
    # Libera a memória de conexões que atingiram timeout de forma mais agressiva.
    reset_timedout_connection on;

    # Define o upstream (grupo de servidores backend).
    upstream api_backend {
        server app1:3001;
        server app2:3002;

        # Mantém um cache de 1000 conexões abertas e ociosas para cada worker
        # com os servidores de backend, eliminando o custo do handshake TCP.
        keepalive 510;
    }

    server {
        listen 9999;

        location / {
            # Habilita o buffering. O Nginx lê a resposta inteira da API
            # e libera a conexão com o backend imediatamente. Essencial para alto throughput.
            proxy_buffering on;

            # Habilita o uso de HTTP/1.1 e do pool de keepalive definido no upstream.
            proxy_http_version 1.1;
            proxy_set_header Connection ""; # Garante o reuso da conexão keep-alive.

            # Encaminha a requisição para o grupo de servidores.
            proxy_pass http://api_backend;
        }
    }
}